# üß† PAM Project Architecture (Digital Twin)

Ce document d√©crit l'architecture technique du projet PAM pour permettre √† une IA de comprendre rapidement le contexte, les d√©pendances et le flux de donn√©es.

## üìå √âtat Actuel : "Compatibility Mode"
Le projet utilise actuellement **OpenCV Native (Haar Cascades)** au lieu de MediaPipe pour assurer une compatibilit√© maximale (probl√®mes rencontr√©s avec Python 3.12 + MediaPipe sous Linux).
Nous utilisons une **vid√©o pr√©-enregistr√©e** (`12099.mp4`) en entr√©e car la webcam n'est pas d√©tect√©e sur la machine h√¥te.

## üìÇ Structure des Fichiers

### `main.py` (Orchestrateur)
* **R√¥le :** Point d'entr√©e. Charge la vid√©o, initialise les modules, g√®re la boucle principale et l'affichage (GUI).
* **Logique :**
    1.  Lit une frame de la vid√©o.
    2.  Envoie la frame √† `FaceDetector`.
    3.  Re√ßoit les donn√©es d'analyse (position, ouverture bouche/yeux).
    4.  Envoie ces donn√©es √† `AvatarRenderer`.
    5.  Affiche deux fen√™tres OpenCV (`Camera` et `Avatar`).
* **Sp√©cificit√© :** G√®re le redimensionnement de l'affichage pour √©viter que les vid√©os 4K ne d√©passent de l'√©cran.

### `src/face_detector.py` (Vision)
* **R√¥le :** Analyse l'image pour extraire les metrics du visage.
* **Technologie :** `cv2.CascadeClassifier` (Haar Cascades).
* **Sortie (Dictionnaire `data`) :**
    * `detected` (bool) : Visage trouv√© ?
    * `x, y, w, h` : Bounding box du visage.
    * `frame_w, frame_h` : Dimensions de la vid√©o source (pour le ratio).
    * `left_openness`, `right_openness` (0.0 ou 1.0) : D√©tection binaire des yeux (bas√©e sur `haarcascade_eye`).
    * `mouth_openness` (float 0.0 -> 1.0) : Calcul√©e par **thresholding** (comptage de pixels noirs dans le tiers inf√©rieur du visage).

### `src/avatar.py` (Rendu)
* **R√¥le :** Dessine l'avatar vectoriel (cercles, lignes) sur un canvas noir.
* **Logique :**
    * **Centrage forc√© :** L'avatar reste au centre de sa fen√™tre (300, 300).
    * **Zoom adaptatif :** La taille de la t√™te d√©pend du ratio `largeur_visage / largeur_video` (plus on est pr√®s, plus c'est gros).
    * **Animation :** Les yeux et la bouche r√©agissent aux donn√©es du d√©tecteur.

## üîÑ Flux de Donn√©es (Data Flow)

1.  **Input :** `frame` (Image BGR depuis `12099.mp4`)
2.  **Processing :** `FaceDetector.process(frame)` -> `face_data` (Dict)
3.  **Rendering :** `AvatarRenderer.draw(face_data)` -> `avatar_img` (Image BGR)
4.  **Output :** Affichage via `cv2.imshow`.

## ‚ö†Ô∏è Notes pour l'IA suivante
* Si vous devez repasser sur **MediaPipe**, il faut g√©rer le conflit de version `protobuf` et l'importation `mp.solutions` sur Python 3.12.
* Le fichier `src/geometry.py` est actuellement **inutilis√©** dans cette version Haar Cascade (il servait pour les calculs d'angles Vectoriels de MediaPipe).
